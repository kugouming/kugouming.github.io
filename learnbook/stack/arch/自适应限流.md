# 1.背景

服务的处理能力是有上限的。当请求速度超过服务的处理速度时，服务就会过载。导致越来越多的请求积压，最终所有的请求都必须等待较长时间才能被处理，从而使整个服务处于瘫痪状态。

如果直接拒绝掉一部分请求，反而能够让服务能够"及时"处理更多的请求。对应的方法就是[设置最大并发](https://github.com/brpc/brpc/blob/master/docs/cn/server.md#%E9%99%90%E5%88%B6%E6%9C%80%E5%A4%A7%E5%B9%B6%E5%8F%91)。

自适应限流能动态调整服务的最大并发，在保证服务不过载的前提下，让服务尽可能多的处理请求。

**使用自适应限流前建议做到：**
- 客户端开启了重试功能。
- 服务端有多个节点。

这样当一个节点返回过载时，客户端可以向其他的节点发起重试，从而尽量不丢失流量。

# 2.计算公式

## 2.1.名词解释

**concurrency**: 同时处理的请求数，又被称为“并发度”。

**max_concurrency**: 框架设置的最大并发度。超过并发的请求会被拒绝（brpc 返回ELIMIT错误）

**best_max_concurrency（最终目标）**: 并发的物理含义是任务处理槽位，天然存在的上限。（若max_concurrency设置的过大，则concurrency可能大于best_max_concurrency，任务将无法被及时处理而暂存在各种队列中排队。若max_concurrency设置的过小，则concurrency总是会小于best_max_concurrency，限制系统达到本可以达到的更高吞吐。）

**noload_latency（目标）**: 单纯处理任务的延时，不包括排队时间。另一种解释是低负载的延时。

**min_latency**: 实际测定的latency中的较小值，当concurrency不大于best_max_concurrency时，min_latency和noload_latency接近(可能轻微上升）。

**peak_qps（目标）**: 服务可处理的 qps的上限。best_max_concurrency / noload_latency。

**max_qps**: 实际测定的qps中的较大值。由于qps具有上限，max_qps总是会小于peak_qps，不论拥塞与否。

## 2.2. 限流原则

在服务处于稳定状态时: concurrency = latency * qps。 这是自适应限流的理论基础。

当服务没有超载时，随着流量的上升，latency基本稳定(接近noload_latency)，qps和concurrency呈线性关系一起上升。

当流量超过服务的peak_qps时，则concurrency和latency会一起上升，而qps会稳定在peak_qps。

假如一个服务的peak_qps和noload_latency都比较稳定，那么它的best_max_concurrency = noload_latency * peak_qps。

自适应限流就是要找到服务的noload_latency和 peak_qps。

## 2.3.计算公式

自适应限流会不断的对请求进行采样，当采样窗口的样本数量足够时，会根据样本的平均延迟和服务当前的qps计算出下一个采样窗口的max_concurrency:

![](../../stack/arch/_assets/Pasted-image-20230524191535.png)

**alpha** 是可接受的延时上升幅度，默认0.3

**latency** 是当前采样窗口内所有请求的平均latency。框架采集

**max_qps** 是最近一段时间测量到的qps的极大值。通过计算获得

**min_latency** 是最近一段时间测量到的latency较小值，是noload_latency的估算值。通过计算获得

当服务处于低负载时，min_latency约等于noload_latency，此时计算出来的max_concurrency会高于concurrency，但低于best_max_concurrency，给流量上涨留探索空间。而当服务过载时，服务的qps约等于max_qps，同时latency开始明显超过min_latency，此时max_concurrency则会接近concurrency，并通过定期衰减避免远离best_max_concurrency，保证服务不会过载。

**2.3.1. 估算noload_latency**  
每隔一段时间缩小max_concurrency，过一小段时间后以此时的latency作为noload_latency。

缩小max_concurrency和公式中的alpha存在关联。让我们做个假想实验，若latency极为稳定并都等于min_latency，那么公式简化为max_concurrency = max_qps * latency (1 + alpha)。qps最多为max_qps * (1 + alpha)，alpha是qps的"探索空间"，若alpha为0，则qps被锁定为max_qps，算法可能无法探索到peak_qps。但在qps已经达到peak_qps时，alpha会使延时上升，此时测定的min_latency会大于noload_latency，一轮轮下去最终会导致min_latency不收敛。定期降低max_concurrency就是阻止这个过程，并给min_latency下降提供"探索空间"。（这里理解成max_concurrency公式不会自己收敛一个固定值即可）

**减少重测时的流量损失**

由于max_concurrency < concurrency时，服务会拒绝掉所有的请求，限流算法将"排空所有的经历过排队等待的请求的时间" 设置为 latency * 2 ，以确保用于计算min_latency的样本绝大部分都是没有经过排队等待的。

由于服务的latency通常都不会太长，这种做法所带来的流量损失也很小。

**应对抖动**  
即使服务自身没有过载，latency也会发生波动，latency的波动会导致server的concurrency发生波动。

我们在设计自适应限流的计算公式时，考虑到了latency发生抖动的情况:当latency与min_latency很接近时，根据计算公式会得到一个较高max_concurrency来适应concurrency的波动，从而尽可能的减少“误杀”。同时，随着latency的升高，max_concurrency会逐渐降低，以保护服务不会过载。  
为了减少个别窗口的抖动对限流算法的影响，同时尽量降低计算开销，使用EMA来进行平滑处理：

EMA（Exponential Moving Average）是指数[移动平均值](https://baike.baidu.com/item/%E7%A7%BB%E5%8A%A8%E5%B9%B3%E5%9D%87%E5%80%BC/10533531)。也叫 EXPMA 指标，它也是一种[趋向类指标](https://baike.baidu.com/item/%E8%B6%8B%E5%90%91%E7%B1%BB%E6%8C%87%E6%A0%87/5376630)，指数移动平均值是以指数式递减加权的移动平均。

// 计算min_latency
```go
if latency > min_latency:  
    min_latency = latency * ema_alpha  + (1 - ema_alpha) * min_latency  
else:  
    do_nothing

```
  
**2.3.2.估算peak_qps  
提高qps增长的速度**  
当服务启动时，由于服务本身需要进行一系列的初始化，tcp本身也有慢启动等一系列原因。服务在刚启动时的qps一定会很低。这就导致了服务启动时的max_concurrency也很低。而按照上面的计算公式，当max_concurrency很低的时候，预留给qps增长的冗余concurrency也很低(即：alpha max_qps min_latency)。从而会影响当流量增加时，服务max_concurrency的增加速度。

假如从启动到打满qps的时间过长，这期间会损失大量流量。在这里我们采取的措施有两个，

采样方面，一旦采到的请求数量足够多，直接提交当前采样窗口，而不是等待采样窗口的到时间了才提交  
计算公式方面，当current_qps > 保存的max_qps时，直接进行更新，不进行平滑处理。在进行了这两个处理之后，绝大部分情况下都能够在2秒左右将qps打满。  
平滑处理  
为了减少个别窗口的抖动对限流算法的影响，同时尽量降低计算开销，通过使用EMA来进行平滑处理：

// 计算max_qps
```go
if current_qps > max_qps:  
    max_qps = current_qps  
else:  
    max_qps = current_qps * ema_alpha / 10 + (1 - ema_alpha / 10) * max_qps
```
  
将`max_qps`的`ema`参数置为`min_latency`的`ema`参数的十分之一的原因是: `max_qps` 下降了通常并不意味着极限qps也下降了。而 `min_latency`下降了，通常意味着`noload_latency`确实下降了。

### **2.3.3. 参考** kratos 自适应限流分析

- `cpu > 800` : 表示 CPU 负载大于 80% 进入限流,这里是800，而不是0.8，因为在计算的时候，源码中乘了个1e3，地址在 cgroupCPU 的 Usage方法中 `aegis/pkg/cpu/cgroup_cpu.go` 文件中  
- `(Now - PrevDrop) < 1s` : 这个表示只要触发过 1 次限流，那么 1s 内都会去做限流的判定，这是为了避免反复出现限流恢复导致请求时间和系统负载产生大量毛刺  
- `(MaxPass * MinRt * windows / 1000) < InFlight` : 判断当前负载是否大于最大负载  
- `InFlight` : 表示当前系统中有多少请求  
- `(MaxPass * MinRt * windows / 1000)` :表示过去一段时间的最大负载  
- `MaxPass` : 表示最近 5s 内，单个采样窗口中最大的请求数  
- `MinRt` : 表示最近 5s 内，单个采样窗口中最小的响应时间  
- `windows` : 表示一秒内采样窗口的数量，默认配置中是 5s 50 个采样，那么 windows 的值为 10。

# 3.框架实现

框架实现分 2 层：
1. 基础功能层：这个不区分协议，所有 server 都可以使用。
2. server 适配层：这个针对 server 有不同的落地方案。比如 http server 使用的是 http server 的中间件，pbrpc server 使用的是其 interceptor.

## 3.1.基础功能层

限流器定义
```go
type FlowLimiter struct {

	mu    sync.RWMutex

	alpha float64 // 为可接受的延时上升幅度，默认0.3

	totaldMeta *calculateMeta // 总计算物料，

	qpsGather     *qpsGath

	latencyGather *latencyGath

}
```

计算物料
```go
type calculateMeta struct {

	maxConcurrency float64 // 设置的最大并发度。超过并发的请求会被拒绝

	minLatency float64 // 低负载的延时, 以秒为单位，统一成浮点类型

	maxQPS     float64 // 实际测定的qps中的较大值。由于qps具有上限，max_qps总是会小于peak_qps，不论拥塞与否

}
```

拦截流量主逻辑
```go
// Keep 继续执行，一般在拦截器前端判断

func (fl *FlowLimiter) Keep(ctx context.Context, info *GatherInfo) bool {

	qps := fl.qps(info.Method)

	avgLatency := fl.avgLatency(info.Method)

	if qps <= 0 || avgLatency <= 0 {

		return true

	}

	// 当前并发度

	concurrency := qps * avgLatency

	masxQPS := fl.masxQPS(info.Method)

	minLatency := fl.minLatency(info.Method)

	// 并发读阈值

	maxConcurrency := masxQPS * minLatency

	// 当前并发度小于阈值，则非限流

	return concurrency < maxConcurrency

}

func (fl *FlowLimiter) HandleDone(ctx context.Context, info *GatherInfo) {

	fl.qpsGather.HandleDone(ctx, info)

	fl.latencyGather.HandleDone(ctx, info)

	_ = fl.updateMaxQPS(info.Method)

	_ = fl.updateMinLatency(info.Method)

}
```

## 3.2.适配层

以 HTTP 为例：

ghttp 增加一个限流中间件
```go
// NewFlowLimitMiddleWareFunc 默认的用于自适应限流的中间件

func NewFlowLimitMiddleWareFunc(conf flowlimit.Config) MiddleWareFunc {

	// 新建自适应限流器

	fl := flowlimit.NewFlowLimiter(conf)

	return func(ctx context.Context, w Writer, req Request, next MiddleWareQueue) bool {

		info := &flowlimit.GatherInfo{

			Start:  time.Now(),

			Method: req.Path(),

		}

		// 在业务逻辑执行完成后打印日志

		defer func() {

			info.End = time.Now()

			fl.HandleDone(ctx, info)

		}()

		return fl.Keep(ctx, info) && next.Next(ctx, w, req)

	}

}
```

中间件注册
```go
router.Use(ghttp.NewFlowLimitMiddleWareFunc(flowlimit.Config{}))
```
# 4. 问题

1.每次请求计算 `max_qps` 和 `min_latency` 效果较好，但是性能上可能有问题

2.是否要支持 `method` 级别的限流，会使得复杂度提升

3.服务刚启动时候（2s 以内）qps 还未打满，通过 qps 计算的并发度会导致流量损失